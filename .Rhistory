facets = c("pop"),
#sigma = 100, #sliding window size in kb
#step = 200, #defulat = sigma*2 (non-overlapping windows)
par = 5, #number cores
#triple_sigma = F, #this is for smoothing, calcualtes average in window of 3xsigma
global = T #use this to just calculate global
)
get.snpR.stats(dat)
?get.snpR.stats
get.snpR.stats(dat, stats = "calc_tajimas_d")
get.snpR.stats(dat, stats = "tajimas_d")
#bi-allelic snpRdata with 424811 SNPs and 115 samples.
#Calculated statistics can be accessed via get.snpR.stats()
#
# note that this is about half of the SNPs we get when including mac==1
#
calc_tajimas_d(
dat,
facets = c("pop"),
#sigma = 100, #sliding window size in kb
#step = 200, #defulat = sigma*2 (non-overlapping windows)
par = 5, #number cores
#triple_sigma = F, #this is for smoothing, calcualtes average in window of 3xsigma
global = T #use this to just calculate global
)
get.snpR.stats(dat, stats = "tajimas_d", facets = c("pop"))
get.snpR.stats(dat, stats = "global_tajimas_d", facets = c("pop"))
get.snpR.stats(dat, stats = "tajimas_d", facets = c("pop"))
#bi-allelic snpRdata with 424811 SNPs and 115 samples.
#Calculated statistics can be accessed via get.snpR.stats()
#
# note that this is about half of the SNPs we get when including mac==1
#
calc_tajimas_d(
dat,
facets = c("pop", "chr"),
sigma = 100, #sliding window size in kb
step = 200, #defulat = sigma*2 (non-overlapping windows)
par = 5, #number cores
triple_sigma = F, #this is for smoothing, calcualtes average in window of 3xsigma
global = F #use this to just calculate global
)
get.snpR.stats(dat, stats = "tajimas_d", facets = c("pop"))
get.snpR.stats(dat, stats = "tajimas_d", facets = c("pop", "chr"))
get.snpR.stats(dat, stats = "tajimas_d")
get.snpR.stats(dat, "pop")
get.snpR.stats(dat, "pop", "tajimas_d")
get.snpR.stats(dat)
foo = get.snpR.stats(dat)
str(foo)
#bi-allelic snpRdata with 424811 SNPs and 115 samples.
#Calculated statistics can be accessed via get.snpR.stats()
#
# note that this is about half of the SNPs we get when including mac==1
#
foo = calc_tajimas_d(
dat,
facets = c("pop", "chr"),
#sigma = 100, #sliding window size in kb
#step = 200, #defulat = sigma*2 (non-overlapping windows)
par = 5, #number cores
#triple_sigma = F, #this is for smoothing, calcualtes average in window of 3xsigma
global = T #use this to just calculate global
)
foo
get.snpR.stats(dat, "chr.pop", "tajimas_d")
get.snpR.stats(dat, "chr.pop", "global_tajimas_d")
get.snpR.stats(dat, "chr.pop", "global_tajimas_d")
str(foo)
get.snpR.stats(dat, "chr.pop", "global_D")
get.snpR.stats(dat, "chr.pop", "tajimas_D")
get.snpR.stats(dat, "weighted.means")
get.snpR.stats(dat, stat = "weighted.means")
foo@weighted.means
q(save="no")
library(dplyr)
library(vcfR)
vcf <- read.vcfR("data/Nf/final_tables/rm_dups/FINAL_snp.IBD_analyses.vcf.gz", verbose = FALSE)
sample_metadata.Nf = read.csv("data/sample_metadata/Nf_filtered.lat_lon_dur_inf.csv")
#pops file is tab-separated sample_name popID
sample_metadata.Nf %>% head
sample_metadata.Nf %>% group_by(state) %>% summarise(n = n())
state_n = sample_metadata.Nf %>% group_by(state) %>% summarise(n = n())
low_n = state_n %>% filter(n < 4)
low_n
sample_metadata.Nf %>% filter(!state %in% low_n) %>% select(Sequence_label, state)
low_n
sample_metadata.Nf %>% filter(!state %in% low_n$state) %>% select(Sequence_label, state)
write.table((sample_metadata.Nf %>% filter(!state %in% low_n$state) %>% select(Sequence_label, state), "data/sample_metadata/Nf.tajD_pops.tsv", sep = "\t", col.names = F, row.names = F, quote = F)
write.table((sample_metadata.Nf %>% filter(!state %in% low_n$state) %>% select(Sequence_label, state)), "data/sample_metadata/Nf.tajD_pops.tsv", sep = "\t", col.names = F, row.names = F, quote = F)
q(save="no")
library(dplyr)
sample_metadata.Nf = read.csv("data/sample_metadata/Nf_filtered.lat_lon_dur_inf.csv")
state_n = sample_metadata.Nf %>% group_by(state) %>% summarise(n = n())
low_n = state_n %>% filter(n < 4)
states = sample_metadata.Nf %>% filter(!state %in% low_n$state) %>% select(state) %>% unique()
for(i in states){
print(i)
}
for(i in states){
file_name = paste0("data/Nf/pixy/", i, ".tajima.tsv")
taj_file_list[[i]] = read.table(file_name, header = T)
}
i
taj_file_list = list()
for(i in states){
file_name = paste0("data/Nf/pixy/", i, ".tajima.tsv")
taj_file_list[[i]] = read.table(file_name, header = T)
}
file_name
for(i in 1:length(states)){
file_name = paste0("data/Nf/pixy/", states[i], ".tajima.tsv")
taj_file_list[[states[i]]] = read.table(file_name, header = T)
}
for(i in 1:length(states)){
file_name = paste0("data/Nf/pixy/", states[i], ".tajima.tsv")
print(file_name)
#taj_file_list[[states[i]]] = read.table(file_name, header = T)
}
states
states = sample_metadata.Nf %>% filter(!state %in% low_n$state) %>% pull(state) %>% unique()
taj_file_list = list()
for(i in 1:length(states)){
file_name = paste0("data/Nf/pixy/", states[i], ".tajima.tsv")
print(file_name)
#taj_file_list[[states[i]]] = read.table(file_name, header = T)
}
for(i in 1:length(states)){
file_name = paste0("data/Nf/pixy/", states[i], ".tajima.tsv")
taj_file_list[[states[i]]] = read.table(file_name, header = T)
}
taj_file_list
taj_df = data.frame(
state = states,
TajimaD = vector(mode = "numeric", length = length(states) )
)
taj_df = data.frame(
state = states,
TajimaD = vector(mode = "numeric", length = length(states) )
)
for(i in 1:length(states)){
file_name = paste0("data/Nf/pixy/", states[i], ".tajima.tsv")
temp = read.table(file_name, header = T)
taj_df[i,"state"] = states[i]
taj_df[i,"TajimaD"] = mean(temp$TajimaD)
}
taj_df
sample_metadata.Nf
sample_metadata.Nf %>% select(state, duration_infection) %>% distinct()
sample_metadata.states = sample_metadata.Nf %>% select(state, duration_infection) %>% distinct()
sample_metadata.states = sample_metadata.Nf %>% select(state, duration_infection) %>% distinct()
left_join(taj_df, sample_metadata.states)
taj.meta = left_join(taj_df, sample_metadata.states)
plot(TajimaD ~ duration_infection)
plot(TajimaD ~ duration_infection, data = taj.meta)
summary(lm(TajimaD ~ duration_infection, data = taj.meta))
taj.meta
taj.meta = left_join(taj_df, sample_metadata.states[-14,])
taj.meta = left_join(taj_df, sample_metadata.states)
plot(TajimaD ~ duration_infection, data = taj.meta[-14,])
summary(lm(TajimaD ~ duration_infection, data = taj.meta[-14,]))
plot(TajimaD ~ duration_infection, data = taj.meta)
summary(lm(TajimaD ~ duration_infection, data = taj.meta))
state_n
state_n %>% print(n = Inf)
low_n = state_n %>% filter(n < 5)
states = sample_metadata.Nf %>% filter(!state %in% low_n$state) %>% pull(state) %>% unique()
taj_df = data.frame(
state = states,
TajimaD = vector(mode = "numeric", length = length(states) )
)
for(i in 1:length(states)){
file_name = paste0("data/Nf/pixy/", states[i], ".tajima.tsv")
temp = read.table(file_name, header = T)
taj_df[i,"state"] = states[i]
taj_df[i,"TajimaD"] = mean(temp$TajimaD)
}
taj_df
sample_metadata.states = sample_metadata.Nf %>% select(state, duration_infection) %>% distinct()
taj.meta = left_join(taj_df, sample_metadata.states)
plot(TajimaD ~ duration_infection, data = taj.meta)
summary(lm(TajimaD ~ duration_infection, data = taj.meta))
taj.meta
state_n
state_n %>% print(n = Inf)
low_n = state_n %>% filter(n < 6)
states = sample_metadata.Nf %>% filter(!state %in% low_n$state) %>% pull(state) %>% unique()
taj_df = data.frame(
state = states,
TajimaD = vector(mode = "numeric", length = length(states) )
)
for(i in 1:length(states)){
file_name = paste0("data/Nf/pixy/", states[i], ".tajima.tsv")
temp = read.table(file_name, header = T)
taj_df[i,"state"] = states[i]
taj_df[i,"TajimaD"] = mean(temp$TajimaD)
}
taj_df
sample_metadata.states = sample_metadata.Nf %>% select(state, duration_infection) %>% distinct()
taj.meta = left_join(taj_df, sample_metadata.states)
plot(TajimaD ~ duration_infection, data = taj.meta)
summary(lm(TajimaD ~ duration_infection, data = taj.meta))
state_ntaj.meta
taj.meta
low_n = state_n %>% filter(n < 4)
states = sample_metadata.Nf %>% filter(!state %in% low_n$state) %>% pull(state) %>% unique()
taj_df = data.frame(
state = states,
TajimaD = vector(mode = "numeric", length = length(states) )
)
for(i in 1:length(states)){
file_name = paste0("data/Nf/pixy/", states[i], ".tajima.tsv")
temp = read.table(file_name, header = T)
taj_df[i,"state"] = states[i]
taj_df[i,"TajimaD"] = mean(temp$TajimaD)
}
taj_df
sample_metadata.states = sample_metadata.Nf %>% select(state, duration_infection) %>% distinct()
taj.meta = left_join(taj_df, sample_metadata.states)
plot(TajimaD ~ duration_infection, data = taj.meta)
summary(lm(TajimaD ~ duration_infection, data = taj.meta))
taj.meta
#no stat sig
#
write.csv("data/Nf/pixy/tajD.vcfkit.csv", row.names = F, quote = F)
#no stat sig
#
write.csv(taj.meta, "data/Nf/pixy/tajD.vcfkit.csv", row.names = F, quote = F)
library(dplyr)
library(vcfR)
#library(adegenet)
library(snpR)
# might need to import dartR, if the gl2snpR conversion fails try loading it
#metadata
sample_metadata.Nf = read.csv("data/sample_metadata/Nf_filtered.lat_lon_dur_inf.csv")
#########
#prev used table of sample,state.name,lat,lon
ind.metrics = sample_metadata.Nf %>% select(Sequence_label, state, lat, lon)
colnames(ind.metrics) = c("sampID", "pop", "lat", "lon")
sub("\\.", "_", ind.metrics$pop) -> ind.metrics$pop #snpR does not accept "." ... beyond annoying
row.names(ind.metrics) = ind.metrics$sampID
#filtered VCF
# bialleles only
# we are now also excluding singletons bc this was causing problems with the conversion to snpR
vcf <- read.vcfR("data/Nf/final_tables/rm_dups/FINAL_snp.mac_ge2.biallele.gwas_analyses.vcf.gz", verbose = FALSE)
gt = extract.gt(vcf, element='GT', as.numeric=TRUE)
gt.pos_list = strsplit(row.names(gt), "_")
gt.pos_df = data.frame(
chr = paste(
lapply(gt.pos_list, function(x) x[1]) %>% unlist,
lapply(gt.pos_list, function(x) x[2]) %>% unlist,
sep = "_"
),
position = lapply(gt.pos_list, function(x) x[3]) %>% unlist,
stringsAsFactors = F
) #note these column names must be chr and position for snpR
#because theres no argument to indicate chr and pos in the tajimaD func
gt = data.frame(gt)
nrow(gt)
nrow(gt.pos_df)
gt[is.na(gt)] = "NN"
head(gt)
dat = import.snpR.data(gt, snp.meta = gt.pos_df, sample.meta = ind.metrics)
vcf <- read.vcfR("data/Nf/final_tables/rm_dups/FINAL_snp.biallele.vcf.gz", verbose = FALSE)
gt = extract.gt(vcf, element='GT', as.numeric=TRUE)
gt.pos_list = strsplit(row.names(gt), "_")
gt.pos_df = data.frame(
chr = paste(
lapply(gt.pos_list, function(x) x[1]) %>% unlist,
lapply(gt.pos_list, function(x) x[2]) %>% unlist,
sep = "_"
),
position = lapply(gt.pos_list, function(x) x[3]) %>% unlist,
stringsAsFactors = F
) #note these column names must be chr and position for snpR
#because theres no argument to indicate chr and pos in the tajimaD func
gt = data.frame(gt)
nrow(gt)
nrow(gt.pos_df)
gt[is.na(gt)] = "NN"
head(gt)
dat = import.snpR.data(gt, snp.meta = gt.pos_df, sample.meta = ind.metrics)
#bi-allelic snpRdata with 424811 SNPs and 115 samples.
#Calculated statistics can be accessed via get.snpR.stats()
#
# note that this is about half of the SNPs we get when including mac==1
#
foo = calc_tajimas_d(
dat,
facets = c("pop", "chr"),
#sigma = 100, #sliding window size in kb
#step = 200, #defulat = sigma*2 (non-overlapping windows)
par = 5, #number cores
#triple_sigma = F, #this is for smoothing, calcualtes average in window of 3xsigma
global = T #use this to just calculate global
)
#foo = get.snpR.stats(dat)
str(foo)
foo@weighted.means
foo@weighted.means %>%
filter(facet == "pop") %>%
select(subfacet, global_ws.theta, global_ts.theta, global_D, global_num_seg)
select(subfacet, global_ws.theta, global_ts.theta, global_D, global_num_seg)
foo@weighted.means %>%
filter(facet == "pop" & !is.na(global_D)) %>%
select(subfacet, global_ws.theta, global_ts.theta, global_D, global_num_seg)
tajD = foo@weighted.means %>%
filter(facet == "pop" & !is.na(global_D)) %>%
select(subfacet, global_ws.theta, global_ts.theta, global_D, global_num_seg)
colnames(tajD)[1] = "state"
sub("_", ".", tajD$state)
tajD$state = sub("_", ".", tajD$state)
write.csv(tajD, "data/Nf/pixy/tajD.snpR.csv", header = T, row.names = F, quote = F)
write.csv(tajD, "data/Nf/pixy/tajD.snpR.csv", row.names = F, quote = F)
state_n = sample_metadata.Nf %>% group_by(state) %>% summarise(n = n())
low_n = state_n %>% filter(n < 2)
low_n
write.table((sample_metadata.Nf %>% filter(!state %in% low_n$state) %>% select(Sequence_label, state)), "data/sample_metadata/Nf.tajD_pops.tsv", sep = "\t", col.names = F, row.names = F, quote = F)
rm(vcf)
rm(dat)
gc()
rm(gt)
gc()
library(dplyr)
dxy = read.table("data/Nf/pixy/pixy_dxy.txt", header = T)
dxy_means = dxy %>%
group_by(pop1, pop2) %>%
summarize(dxy_mean = sum(count_diffs)/sum(count_comparisons))
head(dxy_means)
head(dxy)
?sum
dxy_means = dxy %>%
group_by(pop1, pop2) %>%
summarize(dxy_mean = sum(count_diffs, na.rm = T)/sum(count_comparisons, na.rm = T))
head(dxy_means)
dxy_mat = xtabs(dxy_mean ~ pop1 + pop2, dxy_means)
head(dxy_mat)
dxy_mat
?pivot_longer
library(tidyr)
pivot_wider(dxy_mat, id_cols = c(pop1, pop2), values_from = dxy_means)
head(dxy_means)
pivot_wider(dxy_means, id_cols = c(pop1, pop2), values_from = dxy_mean)
pivot_wider(dxy_means, id_cols = c("pop1", "pop2"), values_from = dxy_mean)
?pivot_wider
pivot_wider(dxy_means, names_from = c("pop1", "pop2"), values_from = dxy_mean)
head(dxy_means)
as.dist(dxy_mat)
head(dxy_means)
dxy_mat = xtabs(dxy_mean ~ pop1 + pop2, dxy_means, drop.unused.levels = T)
head(dxy_mat)
dxy_mat = xtabs(dxy_mean ~ pop2 + pop1, dxy_means, drop.unused.levels = T)
head(dxy_mat)
as.dist(xtabs(dxy_mean ~ pop2 + pop1, dxy_means))
dxy_means
dxy_means %>% filter(pop1 == "CT")
dxy_means %>% filter(pop2 == "CT")
?reshape()
dfr <- reshape(dxy_means, direction="wide", idvar="pop2", timevar="pop1")
head(dfr)
dxy_means
dfr <- reshape(data.frame(dxy_means), direction="wide", idvar="pop2", timevar="pop1")
head(dfr)
#############
as.dist(xtabs(data.frame(dxy_mean) ~ pop2 + pop1, dxy_means))
#############
as.dist(xtabs(dxy_mean ~ pop2 + pop1, data.frame(dxy_means)))
dfr <- reshape(data.frame(dxy_means), direction="wide", idvar="pop2", timevar="pop1")
dxy_means %>% filter(pop2 == "CT" & pop1 == "ME.N")
head(dfr)
head(dxy_mat)
#############
dxy_mat = as.dist(xtabs(dxy_mean ~ pop2 + pop1, data.frame(dxy_means)))
head(dxy_mat)
dxy_mat
dxy_means
dxy_means = dxy %>%
group_by(pop1, pop2) %>%
summarize(dxy_mean = sum(count_diffs, na.rm = T)/sum(count_comparisons, na.rm = T))
dxy_means = dxy %>%
group_by(pop1, pop2) %>%
summarize(dxy_mean = sum(count_diffs, na.rm = T)/sum(count_comparisons, na.rm = T), .groups = "pop2")
dxy_means = dxy %>%
group_by(pop1, pop2) %>%
summarize(dxy_mean = sum(count_diffs, na.rm = T)/sum(count_comparisons, na.rm = T), .groups = "rowwise")
head(dxy_means)
dxy_means = dxy %>%
group_by(pop1, pop2) %>%
summarize(dxy_mean = sum(count_diffs, na.rm = T)/sum(count_comparisons, na.rm = T))
dfr <- reshape(data.frame(dxy_means), direction="wide", idvar="pop2", timevar="pop1")
dfr <- reshape(data.frame(dxy_means), direction="wide", idvar="pop1", timevar="pop2")
head(dfr)
as.dist(dfr)
class(dfr)
dfr
is.na(dfr) %>% rowSums
is.na(dfr) %>% rowSums %>% sort
?sort
dfr[(is.na(dfr) %>% rowSums %>% sort),]
(is.na(dfr) %>% rowSums %>% sort)
(is.na(dfr) %>% rowSums %>% sort)[1]
(is.na(dfr) %>% rowSums %>% sort)[,1]
(is.na(dfr) %>% rowSums %>% sort) %>% names
?order
dfr[order(sort(rowSums(is.na(dfr))),]
dfr[order(rowSums(is.na(dfr)),]
dfr[order(rowSums(is.na(dfr))),]
dfr[order(rowSums(is.na(dfr))),order(colSums(is.na(dfr)))]
dfr[order(rowSums(is.na(dfr)), decreasing = T),order(colSums(is.na(dfr)), decreasing = T)]
dfr[order(rowSums(is.na(dfr)), decreasing = T),order(colSums(is.na(dfr)), decreasing = F)]
dfr.ordered = dfr[order(rowSums(is.na(dfr)), decreasing = T),order(colSums(is.na(dfr)), decreasing = F)]
row.names(dfr.ordered) = dfr.ordered$pop1
dfr.ordered[,-"pop1"]
dfr.ordered[,-1]
#pop1 is the first col
dfr.ordered[,"pop1"] = NULL
dfr.ordered
col.names(dfr.ordered) = sub("dxy_mean.", "", col.names(dfr.ordered))
sub("dxy_mean.", "", colnames(dfr.ordered))
colnames(dfr.ordered) = sub("dxy_mean.", "", colnames(dfr.ordered))
dfr.ordered
as.matrix(dfr.ordered)
dist_mat = as.matrix(dfr.ordered)
dist_mat[is.na(dist_mat)] = 0
as.dist(dist_mat)
as.dist(dfr.ordered)
library(dplyr)
sample_metadata.Nf = read.csv("data/sample_metadata/Nf_filtered.lat_lon_dur_inf.csv")
state_n = sample_metadata.Nf %>% group_by(state) %>% summarise(n = n())
state_n %>% print(n = Inf)
low_n = state_n %>% filter(n < 2)
#tried up to 5
#in our original dataset where we had sig negative relationship
#there were only seven sites
#see the massmyco presentation from 2021
states = sample_metadata.Nf %>% filter(!state %in% low_n$state) %>% pull(state) %>% unique()
taj_df = data.frame(
state = states,
TajimaD = vector(mode = "numeric", length = length(states) )
)
for(i in 1:length(states)){
file_name = paste0("data/Nf/pixy/", states[i], ".tajima.tsv")
temp = read.table(file_name, header = T)
taj_df[i,"state"] = states[i]
taj_df[i,"TajimaD"] = mean(temp$TajimaD)
}
taj_df
sample_metadata.states = sample_metadata.Nf %>% select(state, duration_infection) %>% distinct()
taj.meta = left_join(taj_df, sample_metadata.states)
plot(TajimaD ~ duration_infection, data = taj.meta)
summary(lm(TajimaD ~ duration_infection, data = taj.meta))
#no stat sig
#
write.csv(taj.meta, "data/Nf/pixy/tajD.vcfkit.csv", row.names = F, quote = F)
dxy.dist = as.dist(dfr.ordered)
###################
#setting up geo distance
#ind.metrics = sample_metadata.Nf %>% select(Sequence_label, state, lat, lon)
site_dat = sample_metadata.Nf %>%
select(state, lat, lon) %>%
#filter(!state %in% low_n_states) %>%
#select(!Sequence_label) %>%
distinct
site_dat
colnames(dfr.ordered)
###################
#setting up geo distance
#ind.metrics = sample_metadata.Nf %>% select(Sequence_label, state, lat, lon)
site_dat = sample_metadata.Nf %>%
select(state, lat, lon) %>%
filter(state %in% colnames(dfr.ordered) ) %>%
#filter(!state %in% low_n_states) %>%
#select(!Sequence_label) %>%
distinct
site_dat
###################
#setting up geo distance
#ind.metrics = sample_metadata.Nf %>% select(Sequence_label, state, lat, lon)
site_dat = sample_metadata.Nf %>%
select(state, lat, lon) %>%
filter(state %in% colnames(dfr.ordered) ) %>%
#filter(!state %in% low_n_states) %>%
#select(!Sequence_label) %>%
distinct
site_dat
row.names(site_dat) = site_dat$state
rownames(dfr.ordered)
###################
#setting up geo distance
#ind.metrics = sample_metadata.Nf %>% select(Sequence_label, state, lat, lon)
site_dat = sample_metadata.Nf %>%
select(state, lat, lon) %>%
filter(state %in% rownames(dfr.ordered) ) %>%
#filter(!state %in% low_n_states) %>%
#select(!Sequence_label) %>%
distinct
row.names(site_dat) = site_dat$state
site_dat.ordered = site_dat[row.names(dfr.ordered),]
Dgeo = distm(x = site_dat.ordered[,c("lon", "lat")], fun = distVincentyEllipsoid)
library(geosphere)
library(vegan)
Dgeo = distm(x = site_dat.ordered[,c("lon", "lat")], fun = distVincentyEllipsoid)
rownames(Dgeo) = site_dat.ordered$state
colnames(Dgeo) = site_dat.ordered$state
Dgeo = Dgeo/1000
#mantel
mantel(dxy.dist, Dgeo)
#mantel
foo = mantel(dxy.dist, Dgeo)
plot(foo)
dxy_means
q(save="no")
